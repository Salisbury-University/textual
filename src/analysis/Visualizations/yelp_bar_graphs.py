# Project Name(s): English Contextual Baseline Database
# Program Name: yelp_3D_frequencies.py
# Date: 03/11/2023
# Description: Reads in the reviews.json file containing a large subset of the Yelp Review data dump and generates visual information explaining details regarding the dataset

# ================================================================================
# Included libraries
# Pandas: storing data
# ================================================================================

import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
from textblob import TextBlob
import pandas as pd
import collections
import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords
from wordcloud import WordCloud
import matplotlib.pyplot as plt

def remove_punc(input_string):
    # Punctuation string
    punc = '''!()-[]{};:'"\,<>./?@#$%^&*_~'''
    
    cleaned_string = ""

    # If the character is not punctuation append it
    for char in input_string:
        if char not in punc:
            cleaned_string += char

    return cleaned_string

if __name__ == "__main__":    
    # Load csv file, minimize memory usage using chunks
    yelp_review_chunks = pd.read_csv("reviews.csv", chunksize=10000) 

    # Five lists to hold the reviews based on the number of stars
    review_stars = [ [], [], [], [], [] ]

    # 2D list to hold the most common words found in each review
    review_words = [ [], [], [], [], [] ]

    # Stop words
    # List generated by ChatGPT
    stopwords.words("english")

    stop_words = set(stopwords.words("english"))
    stop_words.update(['the', 'be', 'to', 'of', 'and', 'a', 'in', 'that', 'have', 'it', 'for', 'not', 'on', 'with', 'he', 'as', 'you', 'do', 'at', 'this', 'but', 'his', 'by', 'from', 'they', 'we', 'say', 'her', 'she', 'or', 'an', 'will', 'my', 'one', 'all', 'would', 'there', 'their', 'what', 'so', 'up', 'out', 'if', 'about', 'who', 'get', 'which', 'go', 'me', 'i', 'me', 'my', 'mine', 'we', 'us', 'our', 'ours', 'he', 'him', 'his', 'she', 'her', 'hers', 'it', 'its', 'they', 'them', 'their', 'theirs', 'ive', 'im', 'also'])

    # Iterate through the chunks
    for yelp_review_chunk in yelp_review_chunks:

        # Extract the review text based on the number of stars
        for index, row in yelp_review_chunk.iterrows():
            if (row["stars"] == 5.0):
                review_stars[4].append(row["text"])
            elif (row["stars"] == 4.0):
                review_stars[3].append(row["text"])
            elif (row["stars"] == 3.0):
                review_stars[2].append(row["text"])
            elif (row["stars"] == 2.0):
                review_stars[1].append(row["text"])
            else:
                review_stars[0].append(row["text"])
        
    # List the hold the frequency of each word
    word_freq = [ [], [], [], [], [] ] 

    for i in range(len(review_stars)): 
        # Count the occurence of each word
        num_words = collections.Counter(word.lower() for word in remove_punc(" ".join(review_stars[i])).split() if word.lower() not in stop_words)
        most_common = num_words.most_common(25)
        
        for word, freq in most_common:
            review_words[i].append(word)
            word_freq[i].append(freq)
	
    # List the hold the emotional value of each word
    word_sent = [ [], [], [], [], [] ]
    
    # For each review type iterate through all words
    for i in range(len(review_words)):
        for word in review_words[i]:
            blob = TextBlob(word)
            word_sent[i].append(float(blob.sentiment.polarity))

    # Hold the color values of each of the word sentiment values
    sentiment_color_grades = [ [], [], [], [], [] ]
    
    # For each review type iterate through all words
    for i in range(len(word_sent)):
        for sentiment in word_sent[i]:
            # Negative sentiment corresponds to red
            if sentiment < 0:  
                sentiment_color_grades[i].append("red")
            # Positive sentiment corresponds to green
            elif sentiment > 0:
                sentiment_color_grades[i].append("green")
            # 0 corresponds to blue
            else:
                sentiment_color_grades[i].append("blue")

    # Create subsets for the positive and negative words
    positive_words = [ [], [], [], [], [] ]
    positive_freq = [ [], [], [], [], [] ]
    positive_sent = [ [], [], [], [], [] ]
    positive_colors = [ [], [], [], [], [] ]

    negative_words = [ [], [], [], [], [] ]
    negative_freq = [ [], [], [], [], [] ]
    negative_sent = [ [], [], [], [], [] ]
    negative_colors = [ [], [], [], [], [] ]

    # Extract each type of word (neutral are considered positive for the purposes of this visualization)
    for i in range(len(review_words)):
        for j in range(len(review_words[i])):
            if word_sent[i][j] < 0:
                negative_words[i].append(review_words[i][j])
                negative_freq[i].append(word_freq[i][j])
                negative_sent[i].append(word_sent[i][j])
                negative_colors[i].append(sentiment_color_grades[i][j])

                positive_words[i].append(review_words[i][j])
                positive_freq[i].append(word_freq[i][j])
                positive_sent[i].append(0)
                positive_colors[i].append(sentiment_color_grades[i][j])
            else:
                positive_words[i].append(review_words[i][j])
                positive_freq[i].append(word_freq[i][j])
                positive_sent[i].append(word_sent[i][j])
                positive_colors[i].append(sentiment_color_grades[i][j])
                
                negative_words[i].append(review_words[i][j])
                negative_freq[i].append(word_freq[i][j])
                negative_sent[i].append(0)
                negative_colors[i].append(sentiment_color_grades[i][j])

    plt.bar(word_freq[0], positive_sent[0], width=1500, color=positive_colors[0])
    plt.bar(word_freq[0], negative_sent[0], width=1500, color=negative_colors[0])

    for i in range(len(positive_words[0])):
        plt.text(word_freq[0][i], positive_sent[0][i], str(positive_words[0][i]), ha="center", va="bottom")

    for i in range(len(negative_words[0])):
        plt.text(word_freq[0][i], negative_sent[0][i], str(negative_words[0][i]), ha="center", va="bottom")

    plt.xlabel("Frequency")
    plt.ylabel("Sentiment")
    plt.title("Yelp 1 Star Reviews")

    plt.show()
    print("Script done...")
