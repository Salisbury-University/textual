<!DOCTYPE html>
<html lang="en">
	<head>
		<!-- BOILERPLATE AND TITLE -->
		<meta charset="UTF-8">
    		<meta name="viewport" content="width=device-width, initial-scale=1.0">
    		<meta http-equiv="X-UA-Compatible" content="ie=edge">
    		<title>Textual Baseline Database</title>

		<!-- GOOGLE FONTS -->
		<link rel="preconnect" href="https://fonts.googleapis.com">
		<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
		<link href="https://fonts.googleapis.com/css2?family=One&display=swap" rel="stylesheet">

		<link rel="preconnect" href="https://fonts.googleapis.com">
		<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
		<link href="https://fonts.googleapis.com/css2?family=Fjalla+amily=Yanone+Kaffeesatz:wght@300&display=swap" rel="stylesheet">

		<!-- CODE FONT -->
		<link rel="preconnect" href="https://fonts.googleapis.com">
		<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
		<link href="https://fonts.googleapis.com/css2?family=Sora:wght@300&display=swap" rel="stylesheet">

		<!-- CSS STYLING -->
		<link href="style.css" rel="stylesheet">

		<!-- BOOTSTRAP -->
		<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0/dist/css/bootstrap.min.css" rel="stylesheet">
		<script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.9.2/dist/umd/popper.min.js"></script>	
		<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.1/dist/js/bootstrap.min.js" integrity="sha384-Atwg2Pkwv9vp0ygtn1JAojH0nYbwNJLPhwyoVbhoPwBhjQPR5VtM2+xf0Uwh9KtT" crossorigin="anonymous"></script>	
	
	</head>
  	<body id="page_content">
		<!-- MAIN PAGE CONTENT -->
		<main role="main">

			<!-- BOOTSTRAP NAVBAR, ALLOW FOR SIMPLE NAVIGATION AROUND THE PAGE -->
			<nav class="navbar navbar-expand-lg navbar navbar-dark bg-dark" id="navigation_bar">
			  <a class="navbar-brand" href="#" id="nav_title">Textual Baseline Database</a>
			  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavDropdown" aria-controls="navbarNavDropdown" aria-expanded="false" aria-label="Toggle navigation">
			    <span class="navbar-toggler-icon"></span>
			  </button>
			  <div class="collapse navbar-collapse" id="navbarNavDropdown">
			    <ul class="navbar-nav">
			      <li class="nav-item active">
				<a class="nav-link" href="index.html">Home</a>
			      </li>
			      <li class="nav-item dropdown">
				<a class = "nav-link dropdown-toggle" href="#" id="navbarDropdownMenuLink" data-bs-toggle="dropdown" aria-haspopup="true" aria-expanded="false">About</a>
			<div class="dropdown-menu" aria-labelledby="navDropdownMenuLink">
				<a class="dropdown-item" href="about.html">About the Project</a> 
				<a class="dropdown-item" href="meet_team.html">Meet the Team</a>
			</div>
		      </li>
			      <li class="nav-item">
				<a class="nav-link" href="downloads.html">Download</a>
			      </li>
			      <li class="nav-item dropdown">
				<a class="nav-link dropdown-toggle" href="#" id="navbarDropdownMenuLink" data-bs-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
				  Tutorials
				</a>
				<div class="dropdown-menu" aria-labelledby="navbarDropdownMenuLink">
				  <a class="dropdown-item" href="visualizations.html">Visualizations</a>
				  <a class="dropdown-item" href="page_categorization.html">Page Categorization</a>
				  <a class="dropdown-item" href="text_sentiment.html">Text Sentiment</a>
				  <a class="dropdown-item" href="review_analysis.html">Review Analysis</a>
				</div>
			      </li>
			      <!-- LINK TO THE GITHUB REPOSITORY -->
			      <li class="nav-item">
				<a class="nav-link" href="https://github.com/Salisbury-University/textual">GitHub</a>
			      </li>
			    </ul>
			  </div>
			</nav>	

			<!-- REVIEW IMAGE COURTESY OF UNSPLASH.COM -->
			<div class="container" id="review_header_div">
				<img src="review_stock_image.jpg" alt="Stock image of a person holding a phone" id="stock_img">
				<div id="review_header_text">Yelp Review Classification</div>
			</div>

			<div id="review_navbar_border"></div>
						
			<!-- SUB NAVBAR -->
			<div id="review_navbar">
				<a class="btn btn-primary" role="button" id="nav_button_links" onClick="document.getElementById('review_subheader').scrollIntoView();">Network Function</a>
				<a class="btn btn-primary" role="button" id="nav_button_links" onClick="document.getElementById('review_subheader_2').scrollIntoView();">Network Implementation</a>
				<a class="btn btn-primary" role="button" id="nav_button_links" onClick="document.getElementById('review_subheader_3').scrollIntoView();">Using the Model</a>
				<a class="btn btn-primary" role="button" id="nav_button_links" onClick="document.getElementById('review_subheader_4').scrollIntoView();">Download Source Code</a>
			</div>

			<div id="review_navbar_border_2"></div>

			<a class="btn btn-primary" role="button" id="scroll_button" onClick="document.getElementById('navigation_bar').scrollIntoView();">&#9650;</a>

			<!-- PAGE SUBTITLE -->
			<p id="review_analysis_title">What Can We Do With Yelp Reviews?</p>		
			
			<div class="container" id="review_analysis_container">

				<div id="review_analysis_text">
					<p id="review_analysis_paragraph_1" class="review_analysis_paragraph">The Yelp review site provides access to a large collection of reviews across a large variety of categories. In addition to containing the review text, the Yelp review dataset has the number of stars specified in each review. These review rating can be used for aditional analysis, such as training a neural network predict the number of stars a review should have based on its wording.</p>

					<p id="review_analysis_paragraph_2" class="review_analysis_paragraph">The current collection of Yelp reviews in the database contains roughly ~7.5 million reviews, each entry containing the review text, the date posted, the review rating, and additional information. Many kinds of analysis can be done with this data but for the purposes of this application only the reivew's text and rating were used.</p>

					<p id="review_analysis_paragraph_3" class="review_analysis_paragraph">This project looked into predicting a review's rating based on the way its text was worded. With negative sounding reviews primarily being on the lower half of the 5-star scale and the more positive reviews residing on the other. For the purposes of the training the neural network approximately 1.5 million reviews were extracted from the database and formated as comma separated values (.csv).</p>

					<p id="review_analysis_paragraph_4" class="review_analysis_paragraph">The neural network was trained using Google's Cloud Computing Service, Google Colab. After being trained on the reviews the network achieved a training classifaction accuracy of ~85% and a validation accuracy of ~70%. There is still room for improvement with the network's performance, however, for the time being these values are acceptable. An explanation of the network and the source code are available below.</p>
				</div>

				<div id="review_analysis_logo">
					<div id="yelp_logo_div"><img src="yelp_logo.png" alt="Yelp Logo" id="yelp_logo"></div>
				</div>
			</div>

			<div id="review_subheader"><p id="review_subheader_text">How the Network Works</p></div>
	
			<div class="container" id="review_analysis_container_2">
				<div id="review_analysis_img">
					<div id="lstm_div"><img src="LSTM.png" alt="LSTM Network" id="lstm_img"></div>
				</div>

				<div id="review_analysis_text_2">
				<p id="review_analysis_paragraph_5" class="review_analysis_paragraph">The primary backbone of the classifier is a Bidirection Long Short Term Memory Network or an LSTM. A Bidirectional LSTM is a Recurrent Neural Network (RNN) meaing that the network learns using feedback loops. These loops allow the network to share information it learns with other layers, allowing it to have a "memory."</p>

				<p id="review_analysis_paragraph_5" class="review_analysis_paragraph">One problem with tradtional RNNs that the LSTM helps solve is the issue of long-term dependency. The LSTM solves this by using a special network to pass the information learned forward through the network, additionally the network is able to add or remove information it has learned as needed.</p>
		
				<p id="review_analysis_paragraph_6" class="review_analysis_paragraph">The Bidirectional Long Short Term Memory Network futher improves upon the LSTM by allowing inforation within the network to flow both forward and backward. For example if we have a sentence we cannot currently predict such as "I am _____" but later the network sees the sentence "I'm always happy" the LSTM is able to now predict the previously unpredictable blank space by passing information back through the network.</p>
				</div>

			</div>

			<!-- Code implementation sub-section -->
			<div id="review_subheader_2"><p id="review_subheader_2_text">Network Implementation</p></div>	
				
				<div class="container" id="review_analysis_container_3">	
					<div id="review_analysis_text_3">
						<div id="review_analysis_text_3_header">Dataset:</div>
							<p id="review_analysis_paragraph_7" class="review_analysis_paragraph">The Yelp review dataset is a collection of reviews supplied through an official data dump by the Yelp review site. As stated previously, these reviews span a large variety of categories and businesses. As of the time of this project, the Yelp data dump supplied around seven and a half million unique reviews. These reviews contain the text associated with the review and also provides additional metadata such as the data of publishing and the number of stars the reviewer gave to the reviewed establishment.</p>
							<p id="review_analysis_paragraph_8" class="review_analysis_paragraph">To collect the provided data a Python script was written to load in the Yelp reviews data dump (in JSON format) and save each review into the MongoDB database. Processing the data involves opening the JSON file and reading in each rview, the review is saved into a Python list containing all the review content, metadata, and associated tags. The Python list is then pushed into the database using the Python MongoDB library. As of the writing of this documentation the Python script has been run, storing all 7.5 million reviews into the Textual Baseline Database.</p>
							<p id="review_analysis_paragraph_9" class="review_analysis_paragraph">To train the network a small subset of this data was extracted from the database. Using the MongoDB shell 1,000,000 of the reviews were downloaded with their review text and the number of stars associated with it. The data was split in a 80:20 fashion, 200,000 reviews were used for validation and the remaining 800,000 reviews were used to train the network.</p>
					</div>

					<!-- <a href="https://www.flaticon.com/free-icons/server" title="server icons">Server icons created by vectorsmarket15 - Flaticon</a> -->
					<div id="dataset_icon_img">
						<div id="dataset_div"><img src="server_storage.png" alt="Dataset Icon" id="dataset_img"></div>
					</div>
				</div>

				<div class="container" id="review_analysis_container_4">	
					<!-- <a href="https://www.flaticon.com/free-icons/server" title="server icons">Server icons created by vectorsmarket15 - Flaticon</a> -->
					<div id="network_icon_img">
						<div id="network_div"><img src="network_structure.png" alt="An image depicting the structure of the neural network" id="network_img"></div>
					</div>

					<div id="review_analysis_text_4">
						<div id="review_analysis_text_4_header">Network Structure:</div>
							<p id="review_analysis_paragraph_10" class="review_analysis_paragraph">After the dataset was compiled, a network was created to be trained on these reviews. After training the network should be able to make predictions on new data not yet seen. Depicted to the left is a diagram of the network structure. The network begins with an embedding layer, the purpose of this is to convert the words fed into the network into numerical values. This layer may be pretrained or configured to work with a specific set of words such as those found within this Yelp Review dataset.</p>
							<!-- https://medium.com/analytics-vidhya/what-does-it-mean-by-bidirectional-lstm-63d6838e34d9 -->
							<p id="review_analysis_paragraph_11" class="review_analysis_paragraph">The next layer is the Bidirectional Long Short Term Memory (LSTM) layer. This layer takes input from both the left and right side, combining this data to create better predictions. Normally, LSTM networks usually output data directly, however, a bidirectional LSTM will produce output from both its forward and backward layer, this data is given to an activation layer. This output is considered in the final result.</p>

							<!-- https://www.tutorialspoint.com/keras/keras_dropout_layers.htm -->
							<!-- https://towardsdatascience.com/machine-learning-part-20-dropout-keras-layers-explained-8c9f6dc4c9ab -->
							<p id="review_analysis_paragraph_12" class="review_analysis_paragraph">Following the bidirectional LSTM is a dropout layer. The purpose of the dropout layer is to prevent the network from overfitting on its training dataset. The dropout layer randomly sets the weights of neurons within the network to 0. The result of this is the cost function is more senitive to the weights of its neighboring neurons during backpropigation. By doing this the dropout layer works to help a network better generalize on a dataset.</p>

							<!-- https://www.superdatascience.com/blogs/convolutional-neural-networks-cnn-step-3-flattening -->
							<p id="review_analysis_paragraph_13" class="review_analysis_paragraph">After the data has passed through all of the previous layers the output result will be a multi dimensional matrix. Before this data can be fed into a traditional neural network it first must literally be flattened out into an vector. This lengthy vector can then be passed forward into the remainder of the network.</p>
							<!-- https://machinelearningknowledge.ai/keras-dense-layer-explained-for-beginners/ -->
							<p id="review_analysis_paragraph_14" class="review_analysis_paragraph">After being flattened, the data vector is passed into the first of multiple dense layers. Dense layers are the backbone of most neural networks. The dense layer is the part of the network that learns high-level features from the input data. Also known as the fully connected layer, each dense layer recieves input from the previous layer and applies a set of weights and produces a particular output. As the network is trained these weights are adjusted to produce the correct outputs. The Yelp review textual data is passed through a series of dense and dropout layers until a classification is produced.</p>

					</div>
				</div>

				<div class="container" id="review_analysis_container_5">	
					<div id="review_analysis_text_5">
						<div id="review_analysis_text_3_header">Implementation in Python:</div>	
						<p id="code_header" class="review_analysis_paragraph">The following Python source code shows how this network was implemented:</p>
						<p id="review_analysis_paragraph_15" class="review_analysis_paragraph">
							# Define training variables <br/>
							embedding_vector_length = 32 <br/>
							num_classes = 5 <br/><br/>
							
							# Create the model <br/>
							model = Sequential() <br/>
							model.add(Embedding(vocab_size, embedding_vector_length, input_length=X_train.shape[1])) <br/>
							model.add(Bidirectional(LSTM(250, return_sequences=True))) <br/>
							model.add(Dropout(0.2)) <br/>
							model.add(Flatten()) <br/>
						    	model.add(Dense(128, activation='relu')) <br/>
						    	model.add(Dropout(0.2)) <br/>
						   	model.add(Dense(64, activation='relu')) <br/>
						    	model.add(Dense(32, activation='relu')) <br/>
						    	model.add(Dropout(0.2)) <br/>
						    	model.add(Dense(16, activation='relu')) <br/>
							model.add(Dense(num_classes, activation='softmax')) <br/><br/>

						    	# Compile the model using the adam optimizer <br/>
						    	model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) <br/>
						</p>
					</div>
				</div>	
			
			<!-- Model inference sub-section -->
			<div id="review_subheader_3"><p id="review_subheader_3_text">Using the Model</p></div>	
				
			<div class="container" id="review_analysis_container_6">	
				<div id="review_analysis_text_6">
					<p id="review_analysis_paragraph_16" class="review_analysis_paragraph">The following section will breifly explain how to download the source code and run local inference using this model for those interested in experimenting with this dataset.</p>
					<p id="review_analysis_paragraph_17" class="review_analysis_paragraph">To run inference a separate script is used. This script requires two separate components to run, first it requires weights from the trained neural network which will be loaded in order reconstruct the network. Additionally, the values saved by the toeknizer during the initial training are loaded to rebuild the toeknizer. It is important to use the same tokenizer values for the inference as were used for the training. The tokenizer will convert the English text information into numerical values, if the same numerical values are not produced during both training and inference the output of the neural network will be incorrect.</p>
					<p id="review_analysis_paragraph_18" class="review_analysis_paragraph">This code was tested using Python 3.8 on Ubuntu 18.04-LTS running on the Windows Subsystem for Linux (WSL). If problems are encountered attempting to run this code an issue may be submitted to the GitHub and an attempt to resolve it will be made.</p>
					<p id="review_analysis_paragraph_19" class="review_analysis_paragraph">To run inference, the script "run_classifier.py" will be run in the same directory as the model weights (final_output.h5) and the tokenizer values (toeknizer.pickle). A sample review will be fed in as a command line argument, an example of the script being run in a CPU test environment can be seen in the figure below: </p>

					<div id="network_run_img_div">
						<div id="network_div"><img src="output.png" alt="An image depicting a sample run of the network" id="network_run_img"></div>
					</div>


					<p id="review_analysis_paragraph_20" class="review_analysis_paragraph">Futher documentation, source code, and sample weights may be found in the project GitHub under the analysis sub-directory.</p>

				</div>
			</div>

			<!-- Model inference sub-section -->
			<div id="review_subheader_4"><p id="review_subheader_4_text">Downloads</p></div>	

			<!-- DOWNLOAD NAVBAR -->
			<div id="review_download_navbar">
				<a class="btn btn-primary" role="button" id="nav_button_links" href="./review_classifier_training.py" download>Training Script &#9660;</a>
				<a class="btn btn-primary" role="button" id="nav_button_links" href="./run_classifier.py" download>Inference Script &#9660;</a>
			</div>

			<footer class="container" id="su_footer">
				<p>Salisbury University 2022-2023</p>
			</footer>
		</main>
	</body>
</html>
